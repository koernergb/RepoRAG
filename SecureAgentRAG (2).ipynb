{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNctUMbtQ9Ln",
        "outputId": "7a40a60a-f641-4029-97bd-78a23fd05066"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.9.0.post1)\n",
            "Collecting cohere==2.9.1\n",
            "  Using cached cohere-2.9.1-cp310-cp310-linux_x86_64.whl\n",
            "Requirement already satisfied: GitPython==3.1.31 in /usr/local/lib/python3.10/dist-packages (3.1.31)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from cohere==2.9.1) (2.32.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython==3.1.31) (4.0.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython==3.1.31) (5.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->cohere==2.9.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->cohere==2.9.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->cohere==2.9.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->cohere==2.9.1) (2024.8.30)\n",
            "Installing collected packages: cohere\n",
            "  Attempting uninstall: cohere\n",
            "    Found existing installation: cohere 4.36\n",
            "    Uninstalling cohere-4.36:\n",
            "      Successfully uninstalled cohere-4.36\n",
            "Successfully installed cohere-2.9.1\n"
          ]
        }
      ],
      "source": [
        "# First install dependencies\n",
        "!pip install faiss-cpu cohere==2.9.1 GitPython==3.1.31 numpy tqdm\n",
        "!pip install langchain_cohere"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from git import Repo\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "import numpy as np\n",
        "import faiss\n",
        "from typing import List, Dict, Any\n",
        "from google.colab import userdata\n",
        "from langchain_cohere import CohereEmbeddings\n",
        "from langchain.llms import Cohere\n",
        "\n",
        "class SecureAgentRAG:\n",
        "    def __init__(self, cohere_api_key: str):\n",
        "        \"\"\"Initialize the RAG system\"\"\"\n",
        "        self.embeddings = CohereEmbeddings(\n",
        "            model=\"embed-english-v3.0\",\n",
        "            cohere_api_key=cohere_api_key\n",
        "            # input_type=\"search_document\"\n",
        "        )\n",
        "\n",
        "        self.query_embeddings = CohereEmbeddings(\n",
        "            model=\"embed-english-v3.0\",\n",
        "            cohere_api_key=cohere_api_key\n",
        "            # input_type=\"search_query\"\n",
        "        )\n",
        "\n",
        "        self.llm = Cohere(cohere_api_key=cohere_api_key)\n",
        "        self.dimension = 1024\n",
        "        self.index = faiss.IndexFlatL2(self.dimension)\n",
        "        self.texts = []\n",
        "        self.metadata = []\n",
        "\n",
        "    def clone_repository(self, local_path: str = \"./SecureAgent\"):\n",
        "        \"\"\"Clone the SecureAgent repository\"\"\"\n",
        "        repo_url = \"https://github.com/CoderAgent/SecureAgent.git\"\n",
        "        try:\n",
        "            if os.path.exists(local_path):\n",
        "                shutil.rmtree(local_path)\n",
        "            Repo.clone_from(repo_url, local_path)\n",
        "            return local_path\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Failed to clone SecureAgent: {str(e)}\")\n",
        "\n",
        "    def get_file_content(self, file_path: str) -> str:\n",
        "        \"\"\"Read and return file content\"\"\"\n",
        "        encodings = ['utf-8', 'latin-1', 'cp1252']\n",
        "\n",
        "        for encoding in encodings:\n",
        "            try:\n",
        "                with open(file_path, 'r', encoding=encoding) as file:\n",
        "                    return file.read()\n",
        "            except UnicodeDecodeError:\n",
        "                continue\n",
        "        return \"\"\n",
        "\n",
        "    def process_files(\n",
        "        self,\n",
        "        local_path: str,\n",
        "        ignored_dirs: List[str] = ['.git', '__pycache__', 'venv', 'env'],\n",
        "        file_extensions: List[str] = ['.py', '.md', '.txt', '.json', '.yaml', '.yml']\n",
        "    ) -> List[Dict[str, str]]:\n",
        "        \"\"\"Process repository files\"\"\"\n",
        "        documents = []\n",
        "\n",
        "        for root, dirs, files in os.walk(local_path):\n",
        "            dirs[:] = [d for d in dirs if d not in ignored_dirs]\n",
        "\n",
        "            for file in files:\n",
        "                if any(file.endswith(ext) for ext in file_extensions):\n",
        "                    file_path = os.path.join(root, file)\n",
        "                    relative_path = os.path.relpath(file_path, local_path)\n",
        "                    content = self.get_file_content(file_path)\n",
        "\n",
        "                    if content:\n",
        "                        documents.append({\n",
        "                            \"content\": content,\n",
        "                            \"metadata\": {\n",
        "                                \"file_path\": relative_path,\n",
        "                                \"file_type\": os.path.splitext(file)[1]\n",
        "                            }\n",
        "                        })\n",
        "\n",
        "        return documents\n",
        "\n",
        "    def create_chunks(self, documents: List[Dict[str, str]], chunk_size: int = 1000) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Split documents into chunks\"\"\"\n",
        "        chunks = []\n",
        "\n",
        "        for doc in documents:\n",
        "            content = doc[\"content\"]\n",
        "            lines = content.split('\\n')\n",
        "            current_chunk = []\n",
        "            current_length = 0\n",
        "\n",
        "            for line in lines:\n",
        "                if current_length + len(line) > chunk_size and current_chunk:\n",
        "                    chunk_text = '\\n'.join(current_chunk)\n",
        "                    chunks.append({\n",
        "                        \"text\": chunk_text,\n",
        "                        \"metadata\": doc[\"metadata\"]\n",
        "                    })\n",
        "                    current_chunk = []\n",
        "                    current_length = 0\n",
        "\n",
        "                current_chunk.append(line)\n",
        "                current_length += len(line)\n",
        "\n",
        "            if current_chunk:\n",
        "                chunk_text = '\\n'.join(current_chunk)\n",
        "                chunks.append({\n",
        "                    \"text\": chunk_text,\n",
        "                    \"metadata\": doc[\"metadata\"]\n",
        "                })\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def add_to_index(self, chunks: List[Dict[str, Any]]):\n",
        "        \"\"\"Create embeddings and add to FAISS index\"\"\"\n",
        "        batch_size = 50\n",
        "\n",
        "        for i in tqdm(range(0, len(chunks), batch_size)):\n",
        "            batch = chunks[i:i + batch_size]\n",
        "            texts = [chunk[\"text\"] for chunk in batch]\n",
        "\n",
        "            try:\n",
        "                embeddings = self.embeddings.embed_documents(texts)\n",
        "\n",
        "                self.index.add(np.array(embeddings))\n",
        "                self.texts.extend(texts)\n",
        "                self.metadata.extend([chunk[\"metadata\"] for chunk in batch])\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing batch {i}: {str(e)}\")\n",
        "\n",
        "    def query(self, question: str, top_k: int = 3) -> str:\n",
        "        \"\"\"Query the RAG system\"\"\"\n",
        "        try:\n",
        "            query_embedding = self.query_embeddings.embed_query(question)\n",
        "\n",
        "            if len(self.texts) == 0:\n",
        "                return \"No indexed content available to search.\"\n",
        "\n",
        "            D, I = self.index.search(np.array([query_embedding]), min(top_k, len(self.texts)))\n",
        "\n",
        "            context = \"\\n\\n\".join([\n",
        "                f\"[From {self.metadata[i]['file_path']}]:\\n{self.texts[i]}\"\n",
        "                for i in I[0]\n",
        "            ])\n",
        "\n",
        "            response = self.llm.predict(\n",
        "                f\"\"\"Given the following code context, answer the question.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\"\"\"\n",
        "            )\n",
        "\n",
        "            return response.strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Query error: {str(e)}\")\n",
        "            return str(e)\n",
        "\n",
        "    def process_repository(self, local_path: str = \"./SecureAgent\"):\n",
        "        \"\"\"Main function to process repository\"\"\"\n",
        "        try:\n",
        "            print(\"Cloning repository...\")\n",
        "            self.clone_repository(local_path)\n",
        "\n",
        "            print(\"Processing files...\")\n",
        "            documents = self.process_files(local_path)\n",
        "\n",
        "            print(\"Creating chunks...\")\n",
        "            chunks = self.create_chunks(documents)\n",
        "\n",
        "            print(\"Creating embeddings and index...\")\n",
        "            self.add_to_index(chunks)\n",
        "\n",
        "            print(\"Ready for queries!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing repository: {str(e)}\")\n",
        "            raise"
      ],
      "metadata": {
        "id": "oLPuBv9SRISr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get API key\n",
        "from google.colab import userdata\n",
        "COHERE_API_KEY = userdata.get('COHERE_API_KEY')\n",
        "\n",
        "# Initialize and run\n",
        "rag = SecureAgentRAG(cohere_api_key=COHERE_API_KEY)\n",
        "rag.process_repository()\n",
        "\n",
        "# Example queries\n",
        "questions = [\n",
        "    \"What security measures are implemented in the agent?\",\n",
        "    \"How does the system handle untrusted input?\",\n",
        "    \"What logging mechanisms are in place?\"\n",
        "]\n",
        "\n",
        "for question in questions:\n",
        "    print(f\"\\nQuestion: {question}\")\n",
        "    answer = rag.query(question)\n",
        "    print(f\"Answer: {answer}\")\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8XLqa5QcGWB",
        "outputId": "907b242c-d389-48b0-a798-7553c1d38228"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning repository...\n",
            "Processing files...\n",
            "Creating chunks...\n",
            "Creating embeddings and index...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:05<00:00,  1.37s/it]\n",
            "<ipython-input-19-97815529fc70>:150: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = self.llm.predict(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready for queries!\n",
            "\n",
            "Question: What security measures are implemented in the agent?\n",
            "Answer: The secure-agent you referenced is a Node.js implementation of a GitHub API agent that adds additional authentication headers to the requests it makes to the GitHub API. This agent can be used to authenticate requests to the GitHub API, but it does not implement any security measures beyond what the GitHub API itself provides. \n",
            "\n",
            "The agent has various dependencies which are also used to enhance it and these have undergone regular updates to ensure they are secure and free from vulnerabilities. \n",
            "\n",
            "In terms of security measures implemented, the node engine is also strictly monitored and only versions 8 and above are allowed as per the engine requirements. This is to ensure that the agent does not run on older, unsupported nodes which may have vulnerabilities. \n",
            "\n",
            "Other than this, the package does not explicitly state additional security measures it implements and primarily focuses on API authentication.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Question: How does the system handle untrusted input?\n",
            "Answer: The provided code does not explicitly handle untrusted input and therefore it is not clear how it is handled. It is recommended to review the code closely to determine if there are any vulnerabilities or potential ways that untrusted input from an attacker could be executed as code. If the code interacts with untrusted input, you should ensure that it is properly validated, sanitized, or encrypted before use to reduce the risk of security vulnerabilities.  It is also important to keep the dependencies updated to mitigate any potential risks from code execution attacks through package vulnerabilities.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Question: What logging mechanisms are in place?\n",
            "Answer: No logging mechanisms are explicitly mentioned in the provided context, and no logging frameworks or libraries seem to be installed as dependencies in the `package.json` file or `node_modules` directory. \n",
            "\n",
            "If you'd like to incorporate logging functionality in your project, consider installing a logging library like `winston`, `log4js`, or `console.log`, and use it according to the library's documentation.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Interactive query loop\n",
        "while True:\n",
        "    question = input(\"\\nEnter your question (or 'quit' to exit): \")\n",
        "    if question.lower() == 'quit':\n",
        "        break\n",
        "\n",
        "    try:\n",
        "        answer = rag.query(question)\n",
        "        print(f\"\\nAnswer: {answer}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shGTmdiJRIjV",
        "outputId": "43dc8eba-95ad-4420-b8a5-de934515e00b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter your question (or 'quit' to exit): What are some ways we could improve the repo?\n",
            "\n",
            "Answer: Here are some ways we could potentially improve the AI Review Agent repo: \n",
            "\n",
            "1. Add more detailed instructions, including specific terminal commands or code snippets where appropriate, especially for less experienced developers, and those new to Git and GitHub. \n",
            "\n",
            "2. Provide better error handling and troubleshooting guidelines: Include a systematic way to handle errors and exceptions with clear and concise error messages that provide developers with actionable insights. Error messages should help users understand what went wrong and how they can fix it. \n",
            "\n",
            "3. Include a polishing phase to the AI review agent: Allows reviewers to accept default suggestions, extract key information from the PR description and apply any relevant code formatting to their reviews. \n",
            "\n",
            "4. Expand the functionality of the AI Review Agent: There are already intimations in the README.md file that the AI agent is capable of doing more than simply creating PR reviews. Expanding the utility of the app would be a great way to improve the repo overall. \n",
            "\n",
            "5. Increase the efficiency of the agent: Improve the performance of the AI review agent, either by improving the AI model or optimizing the code.\n",
            "\n",
            "6. Provide a detailed demonstration video: While the README.md file does a good job of outlining what the AI Review Agent is and does, a video\n"
          ]
        }
      ]
    }
  ]
}